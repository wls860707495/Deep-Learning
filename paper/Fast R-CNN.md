# Fast R-CNN
## R-CNN（regions with CNN features）
在AlexNet的基础上进行改进，需要解决两个问题：
```
 1、如何利用深度的神经网络去做目标的定位？
 2、如何在一个小规模的数据集上训练能力强劲的网络模型？
```
### 对于目标的定位
借鉴滑动窗口：
```
1、给定一张输入图片，从图片中提取 2000 个类别独立的候选区域。
2、对于每个区域利用 CNN 抽取一个固定长度的特征向量。
3、再对每个区域利用 SVM 进行目标分类。
```
### 相对于架构的三个模块
与系统三个阶段相对应的三个模块
```
1、生产类别独立的候选区域，这些候选区域其中包含了 R-CNN 最终定位的结果。（R-CNN用的是Selective Search）
2、神经网络去针对每个候选区域提取固定长度的特征向量。（在与Alexnet进行兼容时对所有的候选区域实行了统一变换227x227）
3、一系列的 SVM 分类器。
除去Selective Search算法之外，提取候选区域的算法还包括CPMC
```
### Selective Search
Selective Search是用于在region proposal中的。   
其实质上是一种图像分割算法，使用Selective Search算法的过程如下：
```
step 1:根据论文[1]分割的图片画出多个框，把所有框放入列表Region中

step 2:根据相似程度（颜色，纹理，大小，形状等），计算Region中框之间的俩俩形似度，把相似度放入列表A中 --> 即对于列表A存的是各个框的相似度，包括依赖纹理等信息

step 3:从列表A中找出相似度最大的俩个框a,b并且合并

Step 4:把合并的框加入列表Region中，从A中删除和a，b相关的相似度，重复步骤2，直至清空A

最终只需要对Region中的框进行图片分类，可以将数十万的框降低到2000（在R-CNN中）
```
### SVM分类
在对候选区域进行特征向量的提取之后，每一个类别会对应一个SVM的二分类器。在训练完成之后，由于之前的Region Proposal提取出的可能存在重复区域，经过SVM判别之后会产生相同物体多个bounding boxes标注，之后通过非极大值NMS抑制的策略来减少重复标注问题。同时对bounding boxes使用线性回归方法来对位置估计精修。 --> 候选区域指的是一个区域，而bounding boxs则是这个感兴趣区域的四个边界值，即bounding boxs。
## SPPnet
### spatial pyramid pooling（SPPnet中的核心思想）
其思想是将任意尺寸的feature map用三个尺度的金字塔层分别池化，将池化后的结果拼接得到固定长度的特征向量，送入全连接层进行操作。  
即不论其输入feature map的尺寸及大小是多少，在经过spp中的金字塔池化层之后特征均会被变为固定的尺寸。  
```
其会输出固定的尺寸是因为在进行金字塔池化时，其pooling的长宽大小与stride的长短要与输入的图片的长和宽相关。即金字塔池化层的大小以及步长不是一成不变的。
尺度金字塔 + 特征融合
```
对于sppnet能够共享卷积计算，是因为它在卷积之后再进行的候选区域提取，后将候选区域放入金字塔池化层，保证特征向量的尺寸一致。
### SPPnet与R-CNN的不同
在第一步进行候选区域进行提取时步骤相同，而在后面几步，spp不像R-CNN一样，它将整张图像一块进行卷积得到特征图，然后将之前得到的候选区域在提取出的特征图上标注出来，之后通过特有的金字塔池化对每个候选区域进行池化操作，提取出固定长度的特征向量。
## 单层Rol pooling
对于Rol pooling的具体细节实现，在特征图在卷积层中提取出来之后，设特征图中某一个被提取出来的Rol（感兴趣区域）的大小为h x w，而要固定池化为H x W的特征图，那么将Rol分成H x W个小窗格，小窗格的长和宽分别为h/H，w/W。这样保证无论大小是多少的Rol区域，均被Rol pooling成为了H x W大小的的特征图。与Sppnet中不同的是，Sppnet通过多尺度层的池化来调整了输出的大小以便于适应。
## 与Sppnet不同的采样方式
在Fast R-CNN中进行样本的采样时，采用了分层采样，首先对数量为N的图片进行随机采样，然后对每个图片中的R个ROI进行采样。例如：
```
在R-CNN与Sppnet中使用mini-batch进行128个候选区域的采样，它会在所有图像的所有ROI中随机平均取出128个ROI（即在所有图片生成的所有ROI区域中随机取出mini batch个ROI，对其进行训练），而Fast R-CNN则是先对
两张图片进行采样，之后对每张图片采样64个ROI区域。
 --> 这也是为什么sppnet与rcnn反向传播训练难的原因。
```
在训练期间图像会以0.5的概率进行水平反转，不使用数据增强。
## 损失函数
Fast R-CNN使用的是多任务损失函数，其中将经过ROI Pooling之后的各候选区域的特征图分别加入两个全连接层中，一个用于分类损失（交叉熵损失）的计算，另一个用于边框回归的计算。
## ROI Pooling层的反向传播
ROI Pooling与原Pooling的反向传播基本一致，不同的是与前一层相对应的区域。
## SVD
在全连接层处，因为参数量大，使用SVD的数据降维方法，将权重矩阵W（复杂度为u x v）进行SVD分解，则计算复杂度变为u x t  +  v x t，相当于把一个全连接层拆分成两个，中间以一个低维的数据相连。
## 总结
1、


