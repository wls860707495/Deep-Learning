# Faster R-CNN
Faster R-CNN分为两个模块，其中第一个模块为RPN网络，第二个模块为RoI pooling。即我们通过RPN（全卷积神经网络）来在特征图上提取proposals，然后再使用通过Fast R-CNN检测器对目标进行检测。
## FCN
### 全连接层的替换
FCN的核心在于将CNN最后的全连接层设置为1 x 1的 卷积层（即1x1x4096,1x1x4096,1x1x1000）,、直接输出目标物体所属的像素范围。  
### 层与层之间的跳跃结构（目的是为了得到特征图更加细节的部分）
在FCN的结构之中，我们有很多的池化层，包括pool1，pool2，pool3，pool4，pool5等，原本的图像在我们经过conv1，pool1之后，图像变味了原来大小的1/2，同样，在pool2，pool3，pool4，pool5后图像分别变为了原来大小的1/4，1/8，1/16，1/32。此时我们将pool3、pool4、conv7后得到的特征图(在经过conv7之后的这一层得到的图像不叫特征图叫heatMap)保存下来这三层得到的特征图大小不一样，而且在这上面保存出来的三个特征图都包含了图像的不同细节。之后我们将得到的三个特征图分别使用反卷积的方式得到三个与原图大小相同的图像（三个图像分别为conv7后的原图、pool4后的图与conv7后的图融合后的图、pool3+pool4+conv7得到的图）。
### 逐像素预测
我们使用反卷积将最后一个卷积层的feature map进行上采样，使这个feature map恢复至与输入图像相同的尺寸，从而可以对每个像素都产生了一个预测，同时保留了原始输入图像中的空间信息，最后在上采样的特征图上进行逐像素分类。之后逐个像素计算softmax分类的损失，相当于每一个像素对应一个训练样本。  
如何通过这三个卷积得到的每个类别的得分：
```
如果我们想让224×224尺寸的浮窗，以步长为32在384×384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6×6个位置的类别得分。上述的把全连接层转换成卷积层的做法会更简便。如果224×224的输入图片经过卷积层和下采样层之后得到了[7x7x512]的数组，那么，384×384的大图片直接经过同样的卷积层和下采样层之后会得到[12x12x512]的数组。然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出((12 – 7)/1 + 1 = 6)。这个结果正是浮窗在原图经停的6×6个位置的得分！
```
### 网络的损失
在FCN中，网络输入的batchsize为1，也就是说，因为是对逐像素计算损失的，每个像素有一个loss，即每个像素点都是一个分类任务，一个图像就有对应像素点个样本，所以FCN分割任务的batch是一个图片，之后在所有像素点上的分类loss加起来计算一次梯度更新。
### FCN中的结论
在对图像进行反卷积融合时，先从深层的特征图开始融合，然后向外一步步融合（即先融合pool4-->在这里，上采样也进行了三次，每次上采样大小等于将要融合的pool层输出特征之的大小，再融合pool3），这样的效果比一步上采样到位效果要好。
## RPN（区域生成网络） -->  Faster R-CNN的核心



