# FPN
## Resnet(残差网络)
### 残差学习（Resnet的核心）
残差学习单元通过Identity mapping的引入在输入、输出之间建立了一条直接的关联通道，从而使得强大的有参层集中精力学习输入、输出之间的残差。一般我们用F（X,Wi）来表示残差映射，那么输出即为：Y = F（X,Wi） + X。当输入、输出通道数相同时，我们自然可以如此直接使用X进行相加。而当它们之间的通道数目不同时，我们就需要考虑建立一种有效的identity mapping函数从而可以使得处理后的输入X与输出Y的通道数目相同即Y = F(X, Wi) + Ws * X。  
当X与Y通道数目不同时，作者尝试了两种identity mapping的方式。一种即简单地将X相对Y缺失的通道直接补零从而使其能够相对齐的方式，另一种则是通过使用1x1的conv来表示Ws映射从而使得最终输入与输出的通道达到一致的方式。
### 实验网络
一共使用了三种网络。第一种为VGG19网络，另外则是顺着VGG网络思维继续加深其层次而形成的一种VGG朴素网络，共有34个含参层。最后一个则是与上述34层朴素网络相对应的Resnet网络（主要由残差单元来构成）。
## 特征金字塔
### 类似的图像金字塔
 ![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/four_dif_featuremap.png)
其中：  
图a是一个特征图像金字塔，整个过程是先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测（BB的位置）。  
图b是一种改进的思路，因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，而高层的语义信息能够帮助我们准确的检测出目标，所以我们可以利用最后一个卷积层上的feature map来进行预测。--> 但是这种方法因为在深层卷积的过程中会丢失一些细节信息，导致精度相对于图a来说会有所下降。    
图c结构的设置则是同时利用低层特征和高层特征，分别在不同的层同时进行预测。 --> 在一幅图像中可能具有多个不同大小的目标，区分不同的目标可能需要不同的特征，对于简单的目标我们仅仅需要浅层的特征就可以检测到它，而复杂的目标则需要利用复杂的特征来检测。  
图d为本文提出的特征金字塔，我们首先在输入的图像上进行深度卷积，然后对Layer2上面的特征进行降维操作（添加1x1的卷积层来操作），对Layer4上面的特征进行上采样操作，使它们具有相应大小的尺寸，然后对处理后的Layer2和Layer4执行加法操作，将获得的结果输入到Layer5中去 --> 这样可以获得一个强语义信息，提高检测性能。  
### 在Faster R-CNN中的应用
我们利用Faster R-CNN中的共享卷积模块对不同层的特征图进行提取，之后通过FPN的方法来对这些特征图进行融合细化。将这几层取出来的特征图每一个都使用RPN的方法来确定候选区域，之后将这些获得的候选区域分别在融合细化好的特征图上面进行RoI Pooling操作，最后在此基础上连接两个1024层的全连接网络分两个支路，连接对应的分类层和回归层。  
### 横向连接
 ![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/lateral_connection.png)
这里放大的区域就是横向连接，其中1x1卷积核的主要作用是减少卷积核的个数，即feature map的个数，并不会改变feature map尺寸的大小。  
### 自底向上
自底向上的过程实际上就是网络的前向传播过程，在这个前向过程中，feature map的大小在经过某些层后会改变，而在经过其他一些层的时候不会改变，作者将不改变feature map大小的层归为一个stage，因此每次抽出的特征都是每个stage的最后一个层的输出，这样便能够构成特征金字塔。  
### 自顶向下  
在自顶向下的过程中采用的是上采样，其中横向连接则是将上采样的结果和自底向上生成的相同大小的feature map进行融合，在融合之后还会再采用3x3的卷积核对每个融合的结果进行卷积，目的是消除上采样的混叠效应（aliasing effect）。
