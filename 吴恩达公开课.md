# 吴恩达公开课
## 损失函数
衡量的是在单个样本上的表现
## 成本函数
衡量的是在整体样本上的表现，即将所有训练样本损失函数和相加并平均。（被定义为平均值）
## Tensorflow中的padding中的‘SAME’和‘VALID’
其中对于‘SAME’：n(output) = n(input)/S   -->s为1   经卷积后输出：n(图像大小)+2 * p(填充像素大小)-f(filter大小)+1
对于‘VALID’: n(output) = (n(input)-f+1)/S   -->s为1  经卷积后输出：n(图像大小)-f(filter大小)+1
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/output.png)
## 数据集
### 训练集（所用数据量最大）
对模型进行训练。
### 验证集
验证不同的算法，测试那种算法更行之有效
### 测试集（用少量数据）
测试模型的效果
## 偏差与方差
### 方差(数据过拟合)
通过查看训练集误差和验证集误差，便可以诊断一个算法是否具有高方差。
### 偏差(数据欠拟合) 
训练集的拟合程度不高，错误率较高，且验证集中的错误率与训练集中错误率相差不多。
## 优化算法
### mini-batch梯度下降算法
训练集分为很多小的子集（mini-batch），每个子集中都含有很多的样本   
```
训练集较小：batch梯度下降法（<2000）
训练集较大：mini-batch（mini-batch大小一般设置为64，128，256，512）
```
### 指数加权平均
将除了当天之外的其它天的数据进行加权，权重大小不一样得到的效果便不一样。
### 动量梯度下降法
两个超参数，用β控制着指数加权平均数来对dW和db进行处理，之后通过设置α对权重以及偏置项进行更新，能够最小化碗装函数，
### RMSprop(均方根)
此处用的是微分平方的加群平均数，即相比于动量梯度下降法，dW变为了(dW)^2，并且对于W和b的更新公式亦有转变，公式如下
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/RMSprop.png)
### Adam优化算法（Momentum与RMSprop结合）
结合Momentum与RMSprop，与其不同的是，算出两算法相应的Vdw以及Sdw等参数后，需要计算其各自的修正值，之后根据修正值来更新W与b
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/adam.png)
## 对于正则化（L1,L2）
无论怎样，其类似于给权重进行1-α* (λ/m) 得衰减，所以又叫作权重衰减。  
为什么会减少过拟合（原因）：1、直观上理解就是，当w被设置为接近与0得值，而设置的λ较大时，会基本消除这些隐藏单元的影响（实际上这些隐藏单元还在）。2、当λ较大时，w会较小，那么Z的值会几乎处于一个类线性区间内，那么这样简单的类线性网络会很少发生过拟合。
### 学习率衰减
通过衰减学习率，可以在训练初期使梯度以较大步伐进行下降，并且在收敛时不会出现幅度较大的情况。
### BatchNorm
作用：使隐藏单元值得均值和方差标准化
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/BatchNorm.png)
## 如何通过卷积提取的边缘
当我们进行卷积运算时，对于一张图片上不同的灰度值，表现出来得明亮是不一样的，通过filter生成的特征图中的每个灰度值亦不同，由此特出的特征图即为表现出的边缘亮度等。
## LeNet-5
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/LeNet-5.png)
## AlexNet
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/AlexNet.png)
## VGG-16
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/VGG-16.png)
## ResNet残差网络（跳跃连接）
有助于解决梯度消失和梯度爆炸
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/ResNet.png)
架构图：
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/ResNet2.png)
## N in N
即应用1x1卷积的方法。
## 对象定位
对于一个目标分类的情况来讲，一个数y据集的训练集中不能够只有给出它的标签，还要有边界框坐标以及它的宽和高。那么其对于最后的输出不仅要有各个类别标签的概率，还要有这个被分类出的图像的边框高度和宽度以及它的中心点的坐标。  
其中，对于y的输出类别：
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/classify-y.png)
c1、c2、c3分别是pedestrian、car以及motorcycle的类别，Pc表示是1、2、3类还是背景类。
## 特征点识别
在神经网络最后一层多输出几个个值（眼角的边界坐标）.   
```
比如要输出人脸特征时，输出y的那些向量y = [q，l1，l2，l3...]即q表示是否为脸，l1、l2等表示其各个特征点。
```
## 对象检测
### 滑动窗口
原实现：将剪切好的图像并作为标签送入卷积神经网络进行训练，之后使用滑动窗口来对图像的特点进行识别并输出0-1分类。   
滑动实现：将图片剪切橙相应大小的骨片，一点一点的输入到卷积神经网络，直到某个区域识别到汽车。-->我们可以直接对一整个图片进行卷积操作，一次得到所有的预测值来判断是否有相应的物体（使用1x1卷积来代替全连接层的计算来实现的）。  
### Bounding box
将图片分成几x几的网格，每个网格中均使用对象定位以及对象检测，将检测到的窗口的中点分配给中点所在的网格，那么此物体即所属于此网格，表示在这个网格中含有这个物体。（使用精细化的网格可以尽量避免多个物体同时出现在同一个网格之内）
### 非极大值抑制
找出含有最大Iou值得那个边界框，其周围的边界框均会受到抑制。（即只输出概率最大的分类结果）
## Anchor boxes（解决一个格子只能检测一个对象的问题）
预先定义两个不同的Anchor boxes，之后将预测结果和这两个Anchor boxes关联起来，输出y会相应的多加与Anchor boxes数量相同的一系列输出。在对边界框的中点进行各自的分配时，还同时将中点分配给与对象形状交并比最高的anchor box中，
## RPN候选区域算法
先运行图片分割的算法，在图片分割出色块的基础上将每个色块进行分类器的检测，







