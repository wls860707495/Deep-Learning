# 注
## 损失函数
衡量的是在单个样本上的表现
## 成本函数
衡量的是在整体样本上的表现，即将所有训练样本损失函数和相加并平均。（被定义为平均值）
## 语义分割
### CNN
实现的是图像级的识别，即从图像到结果。--->因为在最后三层是全连接的，输出的是一维的向量，丢失了卷积下的二维向量信息。   
即输入一张图片，输出是图片是什么种类的概率。  
### FCN
实现的是像素级别的识别，即对输入图像的每一个像素都进行对应的判断标注，表明这个像素最可能是属于一个什么物体 / 类别。--->其在最后三层改用1X1的卷积来保证不会丢失二维信息。   
在进行卷积时，对于卷积池化完的深层特征来说，其感受野较大时，观察到的边缘信息便会减少；对于卷积池化完的浅特征来说其感受野较小时，观察到的边缘信息会增加。那么我们在对特征图进行上采样时，越是深层特征上采样完的信息越会减少，所以一般会将浅层反卷积信息与深层反卷积信息进行辅助叠加，更好的优化分割结果的精度。   
但FCN还是无法避免有很多问题，比如，精度问题，对细节不敏感，以及像素与像素之间的关系，忽略空间的一致性等问题。   
解决对细节不敏感：“Dilated Convolutions”（空洞卷积）   
解决像素与像素之间的逻辑关系： “条件随机场”（ Conditional Random Field，简称 CRF）的技术作为输出结果的优化后处理手段。其实类似技术种类较多，比如还有马尔科夫随机场 (MRF) 和高斯条件随机场 (G-CRF) 用的也比较多，但原理都较为类似。像素之间联系加入其中，剔除掉明显不符合事实的判断   
```
eg:
“天空”和 “鸟” 这样的像素在物理空间是相邻的概率，应该要比 “天空” 和 “鱼” 这样像素相邻的概率大，那么天空的边缘就更应该判断
为鸟而不是鱼（从概率的角度）。
```
关键特点：  
特征是由编码器中的不同阶段合并而成的，它们在语义信息的粗糙程度上有所不同。  
低分辨率语义特征图的上采样使用经双线性插值滤波器初始化的反卷积操作完成。  
从 VGG16、Alexnet 等分类器网络进行知识迁移来实现语义细分。  
## 一般分割架构
一般的语义分割架构可以被认为是一个编码器-解码器网络。编码器通常是一个预训练的分类网络，像 VGG、ResNet，然后是一个解码器网络。这些架构不同的地方主要在于解码器网络。解码器的任务是将编码器学习到的可判别特征（较低分辨率）从语义上投影到像素空间（较高分辨率），以获得密集分类。
## SegNet
SegNet 的新颖之处在于解码器对其较低分辨率的输入特征图进行上采样的方式。具体地说，解码器使用了在相应编码器的最大池化步骤中计算的池化索引来执行非线性上采样。这种方法消除了学习上采样的需要。经上采样后的特征图是稀疏的，因此随后使用可训练的卷积核进行卷积操作，生成密集的特征图。
### 关键特点
SegNet 在解码器中使用反池化对特征图进行上采样，并在分割中保持高频细节的完整性。   
编码器不使用全连接层（和 FCN 一样进行卷积），因此是拥有较少参数的轻量级网络。   
![rongqi](https://github.com/wls860707495/Deep-Learning/blob/master/img/image.png)
如上图所示，编码器中的每一个最大池化层的索引都被存储起来，用于之后在解码器中使用那些存储的索引来对相应的特征图进行反池化操作。虽然这有助于保持高频信息的完整性，但当对低分辨率的特征图进行反池化时，它也会忽略邻近的信息。
## U-net
U-Net 架构包括一个捕获上下文信息的收缩路径和一个支持精确本地化的对称扩展路径。我们证明了这样一个网络可以使用非常少的图像进行端到端的训练，并且在ISBI神经元结构分割挑战赛中取得了比以前最好的方法（一个滑动窗口的卷积网络）更加优异的性能。我们使用相同的网络，在透射光显微镜图像（相位对比度和 DIC）上进行训练，以很大的优势获得了2015年 ISBI 细胞追踪挑战赛。此外，网络推断速度很快。一个512x512的图像的分割在最新的 GPU 上花费了不到一秒。  
### 关键特点
```
(1)使用全卷积神经网络。(全卷积神经网络就是卷积取代了全连接层，全连接层必须固定图像大小而卷积不用，所以这个策略使得，你可以
输入任意尺寸的图片，而且输出也是图片，所以这是一个端到端的网络。) 
(2)左边的网络contracting path：使用卷积和maxpooling。   
(3)右边的网络expansive path:使用上采样与左侧contracting path ,pooling层的featuremap相结合，然后逐层上采样到392X392的
 大小heatmap。（pooling层会丢失图像信息和降低图像分辨率且是不可逆的操作，对图像分割任务有一些影响，对图像分类任务的影响不
 大，为什么要做上采样？：因为上采样可以补足一些图片的信息，但是信息补充的肯 定不完全，所以还需要与左边的分辨率比较高的图片
 相连接起来（直接复制过来再裁剪到与上采样图片一样大小），这就相当于在高分辨率和更抽象特征当中做一个折衷，因为随着卷积次数增
 多，提取的特征也更加有效，更加抽象，上采样的图片是经历多次卷积后的图片，肯定是比较高效和抽象的图片，然后把它与左边不怎么抽
 象但更高分辨率的特征图片进行连接）-> 此处运用跳跃连接   
(4)最后再经过两次卷积，达到最后的heatmap，再用一个1X1的卷积做分类，这里是分成两类，所以用的是两个神经元做卷积，得到最后的
两张heatmap,例如第一张表示的是第一类的得分（即每个像素点对应第一类都有一个得分），第二张表示第二类的得分heatmap,然后作为
softmax函数的输入，算出概率比较大的softmax类，选择它作为输入给交叉熵进行反向传播训练
```
## DeepLab v1
近来，深度卷积网络在高级视觉任务（图像分类和目标检测）中展示了优异的性能。本文结合 DCNN 和概率图模型来解决像素级分类任务（即语义分割）。我们展示了 DCNN 最后一层的响应不足以精确定位目标边界，这是 DCNN 的不变性导致的。我们通过在最后一层网络后结合全连接条件随机场
来解决糟糕的定位问题。
### 关键特点
提出空洞卷积（atrous convolution）（又称扩张卷积（dilated convolution））。  
在最后两个最大池化操作中不降低特征图的分辨率，并在倒数第二个最大池化之后的卷积中使用空洞卷积。  
使用CRF（条件随机场）作为后处理，恢复边界细节，达到准确定位效果。    
附加输入图像和前四个最大池化层的每个输出到一个两层卷积，然后拼接到主网络的最后一层，达到 多尺度预测效果。    
## DeepLab v2
首先，我们强调上采样过滤器的卷积，或“空洞卷积”，在密集预测任务中是一个强大的工具。空洞卷积允许我们显式地控制在深度卷积神经网络中计算的特征响应的分辨率。它还允许我们有效地扩大过滤器的视野，在不增加参数数量或计算量的情况下引入更大的上下文。其次，提出了一种空洞空间金字塔池化（ASPP）的多尺度鲁棒分割方法。ASPP 使用多个采样率的过滤器和有效的视野探测传入的卷积特征层，从而在多个尺度上捕获目标和图像上下文。第三，结合 DCNNs 方法和概率图形模型，改进了目标边界的定位。DCNNs 中常用的最大池化和下采样的组合实现了不变性，但对定位精度有一定的影响。  
### 关键特点
提出了空洞空间金字塔池化（Atrous Spatial Pyramid Pooling），在不同的分支采用不同的空洞率以获得多尺度图像表征。
## Deeplab v3
在本工作中，我们再次讨论空洞卷积，一个显式调整过滤器视野，同时控制特征相应分辨率的强大工具。为了解决多尺度目标的分割问题，我们串行/并行设计了能够捕捉多尺度上下文的模块，模块中采用不同的空洞率。此外，我们增强了先前提出的空洞空间金字塔池化模块，增加了图像级特征来编码全局上下文，使得模块可以在多尺度下探测卷积特征。提出的 “DeepLab v3” 系统在没有 CRF 作为后处理的情况下显著提升了性能。
### 关键特点


参考于：   
https://www.cnblogs.com/jerrybaby/p/9293419.html   
https://blog.csdn.net/qq_20084101/article/details/80432960



