# 卷积神经网络
对于全连接神经网络，其神经元排列为一条直线，计算y的值时使用的是向量。而卷积神经网络，如训练一张图片时，输入为一张图片，通过两个3*3的filter，其将会生成两个3*3的feature map，这三个feature map即通过卷积层来得到的feature map。  
每个卷积层可以有多个filter，而每个filter中的深度需要和前一个feature map的深度相同。其中卷积层有几个ffilter那么卷积出来就有几个feature map。
## 解决全连接神经网络权重等参数过多以及消除无效的大量权重
局部连接： 这个是最容易想到的，每个神经元不再和上一层的所有神经元相连，而只和一小部分神经元相连。这样就减少了很多参数。
权值共享： 一组连接可以共享同一个权重，而不是每个连接有一个不同的权重，这样又减少了很多参数。
下采样： 可以使用Pooling来减少每层的样本数，进一步减少参数数量，同时还可以提升模型的鲁棒性。
对于图像识别任务来说，卷积神经网络通过尽可能保留重要的参数，去掉大量不重要的参数，来达到更好的学习效果。

     当步幅设置为2的时候，Feature Map就变成2*2了。这说明图像大小、步幅和卷积后的Feature Map大小是有关系的。
## Pooling层

Pooling层主要的作用是下采样，通过去掉Feture Map中不重要的样本，进一步减少参数数量。
```
     eg：Max Pooling
     即在n*n的样本中取最大值，作为采样后的样本值。--->即在4*4的feature map中，Max Pooling即取左上4个格中的一个有最大值的格，而其余右上、左下、右下可以分别取3个最大的值，将4个值拼成2*2的feature map，这样对于4*4的feature map来说就减少了很多的参数量。
 ```
除Max Pooling外，常用的还有Mean Pooling-->即取各样本的平均值。对于深度为D的Feature Map，各层独立做Pooling，因此Pooling后的深度仍然为D。
